{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import fetch_world_bank_data\n",
    "from src.processor import clean_climate_data\n",
    "from config import logger\n",
    "\n",
    "def main():\n",
    "    # Indicateurs à récupérer\n",
    "    indicators = {\n",
    "        \"co2_per_capita\": \"EN.ATM.CO2E.PC\",\n",
    "        \"total_ghg\": \"EN.ATM.GHGT.KT.CE\"\n",
    "    }\n",
    "\n",
    "    for name, code in indicators.items():\n",
    "        logger.info(f\"Traitement de l'indicateur : {name}\")\n",
    "        \n",
    "        # Le loader gère maintenant le cache tout seul\n",
    "        raw_df = fetch_world_bank_data(code)\n",
    "\n",
    "        if raw_df is not None:\n",
    "            cleaned_df = clean_climate_data(raw_df)\n",
    "            \n",
    "            # Sauvegarde du fichier processé\n",
    "            output_path = f\"data/processed/{name}_cleaned.csv\"\n",
    "            cleaned_df.to_csv(output_path, index=False)\n",
    "            logger.info(f\"Fichier final prêt : {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0376d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from typing import Optional\n",
    "from co2_extractor.web_api import CO2Extractor  # Import de VOTRE librairie\n",
    "from config import logger\n",
    "\n",
    "def fetch_world_bank_data(indicator: str, country: str = \"all\") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Utilise la librairie co2-extractor-wb pour récupérer les données.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Appel de la librairie externe pour l'indicateur {indicator}\")\n",
    "    \n",
    "    # Appel de la classe de votre librairie\n",
    "    df = CO2Extractor.get_co2_data(country=country, indicator=indicator)\n",
    "    \n",
    "    if df is not None:\n",
    "        # Cache local (optionnel)\n",
    "        os.makedirs(\"data/raw\", exist_ok=True)\n",
    "        df.to_csv(f\"data/raw/{indicator}.csv\", index=False)\n",
    "        return df\n",
    "    \n",
    "    logger.error(\"La librairie n'a renvoyé aucune donnée.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c71a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from typing import Optional\n",
    "from config import logger, WB_API_URL\n",
    "\n",
    "def is_cache_valid(filepath: str, max_days: int) -> bool:\n",
    "    \"\"\"Vérifie si le fichier de cache est encore valide.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        return False\n",
    "    \n",
    "    # Calcul de l'âge du fichier\n",
    "    file_age_seconds = time.time() - os.path.getmtime(filepath)\n",
    "    return file_age_seconds < (max_days * 86400)\n",
    "\n",
    "def fetch_world_bank_data(indicator: str, country: str = \"all\", force_refresh: bool = False) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Récupère les données avec gestion du cache local.\n",
    "    \"\"\"\n",
    "    raw_path = f\"data/raw/{indicator}.csv\"\n",
    "    os.makedirs(\"data/raw\", exist_ok=True)\n",
    "\n",
    "    # 1. Vérification du cache\n",
    "    if not force_refresh and is_cache_valid(raw_path, max_days=7):\n",
    "        logger.info(f\"Chargement de {indicator} depuis le cache local.\")\n",
    "        return pd.read_csv(raw_path)\n",
    "\n",
    "    # 2. Appel API si pas de cache ou refresh forcé\n",
    "    url = f\"{WB_API_URL}/country/{country}/indicator/{indicator}?format=json&per_page=5000&source=2\"\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Appel réseau vers l'API pour l'indicateur: {indicator}\")\n",
    "        response = requests.get(url, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if isinstance(data, list) and len(data) > 1:\n",
    "            df = pd.DataFrame(data[1])\n",
    "            # Sauvegarde immédiate pour le cache\n",
    "            df.to_csv(raw_path, index=False)\n",
    "            logger.info(f\"Données récupérées et mises en cache : {raw_path}\")\n",
    "            return df\n",
    "        else:\n",
    "            logger.error(f\"Format de réponse invalide pour {indicator}\")\n",
    "            return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Erreur lors de la requête API : {e}\")\n",
    "        # En cas d'erreur réseau, on essaie quand même de charger le cache même s'il est vieux\n",
    "        if os.path.exists(raw_path):\n",
    "            logger.warning(\"Erreur réseau. Utilisation du cache expiré par précaution.\")\n",
    "            return pd.read_csv(raw_path)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14184724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d409a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "class CO2Extractor:\n",
    "    BASE_URL = \"https://api.worldbank.org/v2\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_co2_data(indicator: str, country: str = \"all\") -> Optional[pd.DataFrame]:\n",
    "        # On essaie deux variantes d'URL : avec source=2 (nécessaire pour le CO2) \n",
    "        # et sans (pour les autres indicateurs plus récents)\n",
    "        urls = [\n",
    "            f\"{CO2Extractor.BASE_URL}/country/{country}/indicator/{indicator}?format=json&per_page=1000&source=2\",\n",
    "            f\"{CO2Extractor.BASE_URL}/country/{country}/indicator/{indicator}?format=json&per_page=1000\",\n",
    "             f\"{CO2Extractor.BASE_URL}/country/{country}/indicator/{indicator}?format=json&per_page=5000&source=2\"\n",
    "        ]\n",
    "        \n",
    "        for url in urls:\n",
    "            try:\n",
    "                print(f\"[LIB] Tentative avec : {url}\")\n",
    "                response = requests.get(url, timeout=15)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "\n",
    "                if isinstance(data, list) and len(data) > 1:\n",
    "                    print(f\"[LIB] Succès avec l'indicateur {indicator}\")\n",
    "                    return pd.DataFrame(data[1])\n",
    "                \n",
    "                # Si l'API renvoie une erreur \"Invalid value\", on passe à l'URL suivante\n",
    "                if isinstance(data, list) and len(data) == 1 and 'message' in data[0]:\n",
    "                    print(f\"[LIB] L'URL a échoué (Code {data[0]['message'][0].get('id')}), essai suivant...\")\n",
    "                    continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[LIB] Erreur de connexion : {e}\")\n",
    "                continue\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import fetch_world_bank_data\n",
    "from src.processor import clean_climate_data\n",
    "from config import logger\n",
    "\n",
    "def main():\n",
    "    # Liste d'indicateurs stables\n",
    "    indicators = {\n",
    "        \"co2_per_capita\": \"EN.ATM.CO2E.PC\",   # CO2 par habitant\n",
    "        \"forest_area\": \"AG.LND.FRST.ZS\",      # Surface forestière (%)\n",
    "        \"gdp_per_capita\": \"NY.GDP.PCAP.CD\", # PIB par habitant (pour corréler avec le climat)\n",
    "        \"total_ghg\": \"EN.ATM.GHGT.KT.CE\"   # Emissions totales de GES (kt de CO2 équivalent)\n",
    "    }\n",
    "\n",
    "\n",
    "    for name, code in indicators.items():\n",
    "        logger.info(f\"Traitement de l'indicateur : {name}\")\n",
    "        \n",
    "        # Le loader gère maintenant le cache tout seul\n",
    "        raw_df = fetch_world_bank_data(code)\n",
    "\n",
    "        if raw_df is not None:\n",
    "            cleaned_df = clean_climate_data(raw_df)\n",
    "            \n",
    "            # Sauvegarde du fichier processé\n",
    "            output_path = f\"data/processed/{name}_cleaned.csv\"\n",
    "            cleaned_df.to_csv(output_path, index=False)\n",
    "            logger.info(f\"Fichier final prêt : {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a61bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config import logger\n",
    "\n",
    "def clean_climate_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Nettoie les données brutes de la Banque Mondiale.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame brut issu de l'API.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame nettoyé avec colonnes Country, Year, Value.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    logger.info(\"Début du nettoyage des données...\")\n",
    "    \n",
    "    # Extraire les valeurs des dictionnaires (country et indicator)\n",
    "    df['country_name'] = df['country'].apply(lambda x: x['value'])\n",
    "    df['country_code'] = df['country'].apply(lambda x: x['id'])\n",
    "    \n",
    "    # Sélectionner et renommer les colonnes utiles\n",
    "    df_cleaned = df[['country_name', 'country_code', 'date', 'value']].copy()\n",
    "    df_cleaned.columns = ['country', 'code', 'year', 'co2_value']\n",
    "    \n",
    "    # Convertir les types\n",
    "    df_cleaned['year'] = pd.to_numeric(df_cleaned['year'])\n",
    "    df_cleaned['co2_value'] = pd.to_numeric(df_cleaned['co2_value'])\n",
    "    \n",
    "    # Supprimer les lignes sans valeur\n",
    "    df_cleaned = df_cleaned.dropna(subset=['co2_value'])\n",
    "    \n",
    "    # Trier par pays et année\n",
    "    df_cleaned = df_cleaned.sort_values(['country', 'year'])\n",
    "    \n",
    "    logger.info(f\"Nettoyage terminé. Lignes restantes : {len(df_cleaned)}\")\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b041cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "# Configuration d'un logger local à la librairie\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CO2Extractor:\n",
    "    \"\"\"Librairie pour extraire les données climatiques de la Banque Mondiale.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.worldbank.org/v2\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_co2_data(indicator: str, country: str = \"all\") -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Récupère les données d'un indicateur via l'API Banque Mondiale en testant plusieurs endpoints.\n",
    "        \n",
    "        Args:\n",
    "            indicator (str): Le code de l'indicateur (ex: 'EN.ATM.CO2E.PC').\n",
    "            country (str): Le code du pays (par défaut 'all').\n",
    "            \n",
    "        Returns:\n",
    "            Optional[pd.DataFrame]: DataFrame avec les données ou None si échec.\n",
    "        \"\"\"\n",
    "        urls = [\n",
    "            f\"{CO2Extractor.BASE_URL}/country/{country}/indicator/{indicator}?format=json&per_page=1000&source=2\",\n",
    "            f\"{CO2Extractor.BASE_URL}/country/{country}/indicator/{indicator}?format=json&per_page=1000\"\n",
    "        ]\n",
    "        \n",
    "        for url in urls:\n",
    "            try:\n",
    "                # On remplace print par logger.info (meilleure pratique)\n",
    "                logger.info(f\"Tentative de récupération via : {url}\")\n",
    "                response = requests.get(url, timeout=15)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "\n",
    "                # Vérification de la structure de réponse [metadata, data]\n",
    "                if isinstance(data, list) and len(data) > 1:\n",
    "                    logger.info(f\"Succès avec l'indicateur {indicator}\")\n",
    "                    return pd.DataFrame(data[1])\n",
    "                \n",
    "                # Gestion des messages d'erreur renvoyés dans le JSON\n",
    "                if isinstance(data, list) and len(data) == 1 and 'message' in data[0]:\n",
    "                    msg = data[0]['message'][0].get('value', 'Erreur inconnue')\n",
    "                    logger.warning(f\"L'URL a échoué (Message API : {msg}), essai suivant...\")\n",
    "                    continue\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logger.error(f\"Erreur de connexion pour {url} : {e}\")\n",
    "                continue\n",
    "        \n",
    "        logger.error(f\"Tous les essais ont échoué pour l'indicateur {indicator}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97386a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc67a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "from src.data_loader import fetch_world_bank_data\n",
    "from src.processor import clean_climate_data\n",
    "from config import logger\n",
    "\n",
    "def main():\n",
    "    # 1. Création des dossiers de données s'ils n'existent pas\n",
    "    os.makedirs(\"data/raw\", exist_ok=True)\n",
    "    os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "    # 2. Liste de vos 4 indicateurs\n",
    "    indicators = {\n",
    "        \"co2_per_capita\": \"EN.GHG.CO2.PC.CE.AR5\",   # CO2 par habitant\n",
    "        \"forest_area\": \"AG.LND.FRST.ZS\",            # Surface forestière (%)\n",
    "        \"gdp_per_capita\": \"NY.GDP.PCAP.CD\",         # PIB par habitant\n",
    "        \"total_ghg\": \"EN.GHG.ALL.MT.CE.AR5\"            # Emissions totales de GES 'unité ici est en Mt (Mégatonnes)\n",
    "    }\n",
    "\n",
    "    logger.info(\"DÉMARRAGE DU PIPELINE D'ACQUISITION DES DONNÉES\")\n",
    "\n",
    "    for name, code in indicators.items():\n",
    "        logger.info(f\"--- Analyse de l'indicateur : {name} ({code}) ---\")\n",
    "        \n",
    "        # 3. Acquisition via la librairie (avec gestion du cache)\n",
    "        raw_df = fetch_world_bank_data(code)\n",
    "\n",
    "        if raw_df is not None:\n",
    "            # 4. Nettoyage générique\n",
    "            cleaned_df = clean_climate_data(raw_df)\n",
    "            \n",
    "            if not cleaned_df.empty:\n",
    "                # 5. Sauvegarde du fichier final\n",
    "                output_path = f\"data/processed/{name}_cleaned.csv\"\n",
    "                cleaned_df.to_csv(output_path, index=False)\n",
    "                logger.info(f\"SUCCÈS : Fichier {output_path} créé.\")\n",
    "            else:\n",
    "                logger.warning(f\"Le nettoyage a renvoyé un résultat vide pour {name}.\")\n",
    "        else:\n",
    "            logger.error(f\"ÉCHEC : Impossible de récupérer l'indicateur {name}.\")\n",
    "\n",
    "    logger.info(\"PIPELINE TERMINÉ AVEC SUCCÈS.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climat_env (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
